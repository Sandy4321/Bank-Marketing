{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4f71bda4e4a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearMiss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/bank-additional-full.csv', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at statistics of our data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = (df['y'] == 'yes')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('y', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "    1. Visualizing some of the parameters as to how they are distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visaulizing age in the dataset\n",
    "sns.distplot(df['age'], hist = True, color = \"#07247D\", hist_kws = {'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the marital status\n",
    "sns.countplot(df['marital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking number of categories in education\n",
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing count of education\n",
    "fig_edu = sns.countplot(x = 'education', data = df)\n",
    "fig_edu.set_xticklabels(fig_edu.get_xticklabels(), rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the above two using subplots\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\n",
    "\n",
    "# First plot for marital status\n",
    "sns.countplot(x = \"marital\", data = df, ax = ax1)\n",
    "ax1.set_title(\"marital status distribution\", fontsize = 13)\n",
    "ax1.set_xlabel(\"Marital Status\", fontsize = 12)\n",
    "ax1.set_ylabel(\"Count\", fontsize = 12)\n",
    "\n",
    "# Second plot for Education distribution\n",
    "sns.countplot(x = \"education\", data = df, ax = ax2)\n",
    "ax2.set_title(\"Education distribution\", fontsize = 13)\n",
    "ax2.set_xlabel(\"Education level\", fontsize = 12)\n",
    "ax2.set_ylabel(\"Count\", fontsize = 12)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing how JOBS are distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15,5)\n",
    "sns.countplot(x = \"job\", data = df)\n",
    "ax.set_xlabel('Job', fontsize = 12)\n",
    "ax.set_ylabel('Count', fontsize = 12)\n",
    "ax.set_title(\"Job Count Distribution\", fontsize = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing and Loan Distribution\n",
    "\n",
    "1. Checking how Housing Loans and Personal Loans are distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\n",
    "sns.countplot(x = \"housing\", data = df, ax = ax1, order = ['yes', 'no', 'unknown'])\n",
    "ax1.set_title(\"Housing Loan distribution\")\n",
    "ax1.set_xlabel(\"Housing Loan\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "\n",
    "sns.countplot(x = \"loan\", data = df, ax = ax2, order = ['yes', 'no', 'unknown'])\n",
    "ax2.set_title(\"Personal Loan Distribution\")\n",
    "ax2.set_xlabel(\"Personal Loan\")\n",
    "ax2.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting total count \n",
    "Getting count of number of Defaulters, people with Housing loan and Personal loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit Defaulter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of people with credit default: \", df[df['default'] == 'yes']['default'].count())\n",
    "print(\"Number of people with no credit default: \", df[df['default'] == 'no']['default'].count())\n",
    "print(\"Number of people who's credit default is unknown: \", df[df['default'] == 'unknown']['default'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housing Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of people with Housing loan: \", df[df['housing'] == 'yes']['housing'].count())\n",
    "print(\"Number of people with no Housing loan: \", df[df['housing'] == 'no']['housing'].count())\n",
    "print(\"Number of people who's Housing loan is unknown: \", df[df['housing'] == 'unknown']['housing'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of people with Personal loan: \", df[df['loan'] == 'yes']['loan'].count())\n",
    "print(\"Number of people with no Personal loan: \", df[df['loan'] == 'no']['loan'].count())\n",
    "print(\"Number of people who's Personal loan is unknown: \", df[df['loan'] == 'unknown']['loan'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation related to \"Last Contact of the Current Campain\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Visualisation related to Duration </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting duration using boxplot makes it difficult to obtain some important values like average of distribution and so I am plotting histogram on the side to see how its distributed and check for mean value (If its possible). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\n",
    "\n",
    "sns.boxplot(x = \"duration\", data = df, orient = 'v', ax = ax1)\n",
    "ax1.set_xlabel(\"Calls\")\n",
    "ax1.set_ylabel(\"Duration\")\n",
    "ax1.set_title(\"Call distribution\")\n",
    "\n",
    "sns.distplot(df['duration'], ax = ax2)\n",
    "ax2.set_xlabel(\"Call duration\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.set_title(\"Call Duration vs Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the Mean, Standard Diveation, Minimum and Maximum values for duration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_duration = df['duration'].min()\n",
    "max_duration = df['duration'].max()\n",
    "median_duration = df['duration'].mean()\n",
    "standard_dev_duration = df[\"duration\"].std()\n",
    "\n",
    "print(\"Min call duration: \", min_duration)\n",
    "print(\"Max call duration: \", max_duration)\n",
    "print(\"Median call duration: \", round(median_duration, 2))\n",
    "print(\"Standard diveation in call duration: \", round(standard_dev_duration, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the box plot that most call duration is around the mean so finding the interquartile range will help us in understanding how long the call might last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_quartile = df['duration'].quantile(q = 0.25)\n",
    "second_quartile = df['duration'].quantile(q = 0.50)\n",
    "third_quartile = df['duration'].quantile(q = 0.75)\n",
    "fourth_quartile = df['duration'].quantile(q = 1)\n",
    "IRQ = third_quartile - second_quartile\n",
    "\n",
    "print(\"Second Quartile: \", second_quartile)\n",
    "print(\"Third Quartile: \", third_quartile)\n",
    "print(\"Inter quartile range(range within which most data is present): \",IRQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <i> Visualisation related to \"Contact, Month and Day of the week\" </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For contact and Days of the week\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\n",
    "\n",
    "sns.countplot(x = 'contact', data = df, ax = ax1)\n",
    "ax1.set_xlabel(\"Contact Method\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.set_title(\"Count of Contact Methods\")\n",
    "\n",
    "sns.countplot(df['day_of_week'], ax = ax2)\n",
    "ax2.set_xlabel(\"Days of the week\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.set_title(\"Count of Calls made on Days of the week\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Months\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "sns.countplot(x = 'month', data = df, order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\n",
    "ax.set_xlabel(\"Months\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Count of contacts made in each month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the average duration of call with people holding different jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "sns.boxplot(x = \"job\", y = \"duration\", data = df, orient = 'v')\n",
    "ax.set_xlabel(\"Jobs\")\n",
    "ax.set_ylabel(\"Duration\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"log(Duration) vs Jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if there is a relation between average duration of call and eduacation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "sns.boxplot(x = \"education\", y = \"duration\", data = df, orient = 'v')\n",
    "ax.set_xlabel(\"Education\")\n",
    "ax.set_ylabel(\"Duration\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"log(Duration) vs Education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jobs: \\n\", df[\"job\"].unique(),'\\n')\n",
    "print(\"Marital Status: \\n\", df['marital'].unique(),'\\n')\n",
    "print(\"Education: \\n\", df['education'].unique(),'\\n')\n",
    "print(\"Default on Credit: \\n\", df['default'].unique(),'\\n')\n",
    "print(\"Housing loan: \\n\", df['housing'].unique(),'\\n')\n",
    "print(\"Loan default: \\n\", df['loan'].unique(),'\\n')\n",
    "print(\"Contact type: \\n\", df['contact'].unique(),'\\n')\n",
    "print(\"Months: \\n\", df['month'].unique(),'\\n')\n",
    "print(\"day_of_week: \\n\", df['day_of_week'].unique(),'\\n')\n",
    "print(\"Poutcome: \\n\",df[\"poutcome\"].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating label encoders to treat all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job\"] = labelencoder_X.fit_transform(df[\"job\"])\n",
    "df[\"marital\"] = labelencoder_X.fit_transform(df[\"marital\"])\n",
    "df[\"education\"] = labelencoder_X.fit_transform(df[\"education\"])\n",
    "df[\"default\"] = labelencoder_X.fit_transform(df[\"default\"])\n",
    "df[\"housing\"] = labelencoder_X.fit_transform(df[\"housing\"])\n",
    "df[\"loan\"] = labelencoder_X.fit_transform(df[\"loan\"])\n",
    "df[\"contact\"] = labelencoder_X.fit_transform(df[\"contact\"])\n",
    "df[\"month\"] = labelencoder_X.fit_transform(df[\"month\"])\n",
    "df[\"day_of_week\"] = labelencoder_X.fit_transform(df[\"day_of_week\"])\n",
    "df[\"poutcome\"] = labelencoder_X.fit_transform(df[\"poutcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataframes to display all the columns in the output\n",
    "pd.set_option('max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Undersampling and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['y'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that out of 41k odd entries, we have only 4640 positive instances. Out data is imballenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with imballenced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is imballenced so the output of the model will be biased. One way to move forward is:\n",
    "1. Undersample the data\n",
    "2. Oversample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three types of undersample that we can use. I will be using version 3 for undersampling\n",
    "undersample = NearMiss(version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataframe to be fed into undersample\n",
    "df_x = df.iloc[:,:-1]\n",
    "df_y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting out new data\n",
    "X, y = undersample.fit_resample(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding output column back to X to perform feature selection\n",
    "X['y'] = y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrix heat map to check which feature has greatest influence on the output \n",
    "fig, ax = plt.subplots(figsize = (25, 10))\n",
    "matrix = np.triu(X.corr())\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.1f', vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', mask=matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output has a good correlation with duration, pdays, emp.var.rate, euribor3m and nr.employed. Therefore they might form a very good features compared to others.\n",
    "We should also note that emp.var.rate has a high correlation with nr.employed, euribor3m and cons.price.idx. So we might need to consider this while selecting our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if any categorical variables have direct relationship with y\n",
    "\n",
    "for i in [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"poutcome\"]:\n",
    "    print(\"Results for categorical variable {} is:\\n\".format(i))\n",
    "    print(X.groupby(i)['y'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we cant come to any conclusion but one thing we can observe is that in poutcome, when the value is '2', there is 72.5% positive outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate categorical plots for features\n",
    "X.rename(columns={'y':'Output rate'}, inplace=True)\n",
    "for col in [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"poutcome\"]:\n",
    "    sns.catplot(x=col, y='Output rate', data=X, kind='point', aspect=2, )\n",
    "    plt.ylim(0, 1)\n",
    "X.rename(columns={'Output rate':'y'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs we can see that Housing and loan remains almost constant and dont have much if an effect. So probably we can elemenate them. Lets perform statistical tests to determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_cont_feature(feature):\n",
    "    print('\\n*** Results for {} ***'.format(feature))\n",
    "    print(X.groupby('y')[feature].describe())\n",
    "    print(ttest(feature))\n",
    "    \n",
    "def ttest(feature):\n",
    "    survived = X[X['y']==1][feature]\n",
    "    not_survived = X[X['y']==0][feature]\n",
    "    tstat, pval = stats.ttest_ind(survived, not_survived, equal_var=False)\n",
    "    print('t-statistic: {:.1f}, p-value: {:.3}'.format(tstat, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
    "       'cons.conf.idx', 'euribor3m', 'nr.employed']:\n",
    "    describe_cont_feature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we can see that age, housing and month have p-value greater than 0.5 therefore we can eleminate them as they fail null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries required for Machine learning model\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating X and Y variables for fitting the model\n",
    "y = X.iloc[:,-1]\n",
    "X = X.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns after doing feature scaling\n",
    "X = X.drop([\"age\",\"job\", \"housing\", \"month\", \"loan\", \"campaign\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing all the data to standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train test split to fit and evaluate the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model and fitting it on training data\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data output\n",
    "y_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the precision and accuracy of our model\n",
    "print('precision on the evaluation set: ', precision_score(y_test, y_pred))\n",
    "print('accuracy on the evaluation set: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logestic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model and fitting it on training data\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data output\n",
    "y_pred = model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the precision and accuracy of our model\n",
    "print('precision on the evaluation set: ', precision_score(y_test, y_pred))\n",
    "print('accuracy on the evaluation set: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_log, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision on the evaluation set: ', precision_score(y_test, pred_knn))\n",
    "print('accuracy on the evaluation set: ', accuracy_score(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision on the evaluation set: ', precision_score(y_test, pred1))\n",
    "print('accuracy on the evaluation set: ', accuracy_score(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
